{
  "hash": "4e25751cbdf9872e3f4675e4819450f9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"BCR-ABL Fusion\"\nsubtitle: \"in B-Cell Leukemia\"\ndescription: Study BCR-ABL prediction from gene-expression profiles and evaluate how IPD methods calibrate downstream inference in genomics.\nimage: images/genetics_cover.png\nformat: html\n---\n\n\n\n\n\n\n\n## Background & Motivation\n\nAcute lymphoblastic leukemia (ALL) is the most common childhood cancer, \nbut it exhibits marked genetic heterogeneity, with distinct chromosomal \ntranslocations defining molecular subtypes with divergent prognoses and \ntherapeutic responses. In B-cell lineage ALL, the **BCR-ABL1** fusion \n(\"breakpoint cluster region\"/\"Abelson\", i.e., the \"Philadelphia chromosome\") \narises from a t(9;22) translocation and encodes a constitutively active \ntyrosine kinase. This fusion was historically associated with poor outcomes, \nuntil the advent of targeted therapies (e.g., imatinib) revolutionized \ntreatment and survival.\n\n<br/>\n\n![*Source: https://www.cancer.gov/publications/dictionaries/cancer-terms/def/philadelphia-chromosome*](images/bcrabl1_overview.jpg){width=100%}\n\n<br/>\n\nHigh-density microarray profiling measures expression of over 7,000 genes \nin leukemic blast cells, enabling a form of \"molecular diagnostics\" where \nsupervised learning can:\n\n1. **Classify** fusion status or other genetic subtypes when cytogenetic assays (PCR, FISH) are unavailable.\n2. **Discover** novel marker genes and pathways dysregulated by specific fusions.\n3. **Predict** therapeutic response and stratify risk using expression-derived scores.\n\nHowever, in many retrospective or multi-center cohorts, only a subset of \npatients undergo gold-standard fusion testing (e.g., RT-PCR for BCR-ABL1), \nleaving the majority \"unlabeled.\" A common workaround is to train a gene\nexpression classifier on the small labeled subset and apply it to the larger \nunlabeled cohort. Yet, naive downstream analyses, treating predicted labels \nas ground truth, can yield biased effect estimates and understate uncertainty.\n\n[**Inference with Predicted Data (IPD)**](https://academic.oup.com/bioinformatics/article/41/2/btaf055/7997267) \noffers a principled remedy: it combines a small labeled set with the predicted \nlabels (e.g., with true fusion status) with a larger unlabeled set, adjusting \nboth bias and variance. In this module, we will:\n\n1. **Describe** the [`ALL`](https://www.bioconductor.org/packages/release/data/experiment/html/ALL.html) and [`Golub`](https://www.bioconductor.org/packages/release/data/experiment/manuals/golubEsets/man/golubEsets.pdf) Bioconductor datasets.\n2. **Subset** the `ALL` data to B-cell ALL and filter to the top 500 variable probes.\n3. **Harmonize** probes across platforms via gene symbols.\n4. **Split** the `ALL` data and train three classifiers for BCR-ABL1 fusion status.\n5. **Predict** on the holdout `ALL` and `Golub` B-cell ALL data using the `ALL`-trained classifier.\n6. **Apply** IPD to estimate the association between fusion status and patient sex assigned at birth.\n\nBy the end, you will understand how to leverage expression-based predictions \nwhile maintaining valid inference on genetic subtypes in cohorts with partially \nmissing gold-standard labels. \n\n> **Note:** For the data loading and prediction workflows, we will directly \n> follow the Bioconductor MLInterfaces vignette by VJ Carey and P Atieno:\n>\n>\nhttps://www.bioconductor.org/packages/devel/bioc/vignettes/MLInterfaces/inst/doc/MLprac2_2.html\n\n## Datasets Overview\n\nWe work with two public [Bioconductor](https://www.bioconductor.org/) datasets:\n\n* [**ALL**](https://www.bioconductor.org/packages/release/data/experiment/html/ALL.html) (`ALL` package): 128 samples of acute lymphoblastic leukemia (both B- and T-cell), profiled on the Affymetrix HGU95Av2 microarray. Phenotype data include `BT` (immunophenotype), `mol.biol` (molecular subtype including BCR-ABL1 or NEG), age, and sex.\n* [**Golub_Merge**](https://www.bioconductor.org/packages/release/data/experiment/manuals/golubEsets/man/golubEsets.pdf) (`golubEsets` package): 72 samples of leukemias (ALL vs. AML), profiled on Affymetrix HGU6800. Phenotype data include `ALL.AML`, `T.B.cell` (lineage), age, and sex.\n\nWe will train our classifiers on a subset of the `ALL` data, test the model on \nthe holdout `ALL` data, and perform IPD on the holdout `ALL` and `Golub` data.\n\n## Phenotype Reduction and Feature Filtering\n\nWe first narrow to B-cell ALL samples and reduce dimensionality by keeping the 500 most variable probes.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the ALL data\ndata(ALL)\n\n# Subset ALL to B-cell lineage (BT codes starting with \"B\")\nbALL <- ALL[, substr(pData(ALL)$BT, 1, 1) == \"B\"]\n\n# Keep only fusion-negative (\"NEG\") and fusion-positive (\"BCR/ABL\") samples\nfus <- bALL[, bALL$mol.biol %in% c(\"NEG\", \"BCR/ABL\")]\n\n# Convert to factor with clear levels: NEG=0, BCR/ABL=1\nfus$mol.biol <- factor(fus$mol.biol, levels = c(\"NEG\", \"BCR/ABL\"))\n\n# Compute median absolute deviation (MAD) for each probe\ndevs <- apply(exprs(fus), 1, mad)\n\n# Select top 500 most variable probes by MAD ranking\ntop500 <- order(devs, decreasing = TRUE)[1:500]\n\n# Subset ExpressionSet to top 500 probes\ndat_filt <- fus[top500, ]\n\n# Confirm dimensions: 500 probes x n samples\ndim(exprs(dat_filt))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 500  79\n```\n\n\n:::\n:::\n\n\n\n\n\n> **Explanation:**\n>\n> * `mad()` is robust to outliers and captures variability.\n> * Filtering saves time on downstream analysis without losing key signals.\n> * We now have `dat_filt`, a filtered ALL dataset focused on B-cell lineage and the most informative probes.\n\n## Cross-Platform Probe Harmonization\n\nTo predict on the `Golub` data, which uses a different array, we map probes \nfrom each platform to gene symbols, then intersect to find a common gene set.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the Golub data\ndata(Golub_Merge)\n\n# Map HGU95Av2 probes (ALL) to gene symbols\ngmap_all <- AnnotationDbi::select(\n  hgu95av2.db,\n  keys    = featureNames(dat_filt),\n  columns = c(\"PROBEID\",\"SYMBOL\"),\n  keytype = \"PROBEID\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n'select()' returned 1:many mapping between keys and columns\n```\n\n\n:::\n\n```{.r .cell-code}\n# HGU6800 probes (Golub) to gene symbols\ngmap_golub <- AnnotationDbi::select(\n  hu6800.db,\n  keys    = featureNames(Golub_Merge),\n  columns = c(\"PROBEID\",\"SYMBOL\"),\n  keytype = \"PROBEID\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n'select()' returned 1:many mapping between keys and columns\n```\n\n\n:::\n\n```{.r .cell-code}\n# Identify common symbols\ncommon_sym <- intersect(gmap_all$SYMBOL, gmap_golub$SYMBOL)\n\n# For each symbol, pick the first associated probe\nprobe_all <- gmap_all |> \n  filter(SYMBOL %in% common_sym) |> \n  group_by(SYMBOL) |> \n  dplyr::slice(1) |> \n  drop_na()\n\nprobe_golub <- gmap_golub |> \n  filter(SYMBOL %in% common_sym) |> \n  group_by(SYMBOL) |> \n  dplyr::slice(1) |> \n  drop_na()\n\n# Subset ExpressionSets to these probes\ndat_train  <- dat_filt[probe_all$PROBEID, ]\neset_golub <- Golub_Merge[probe_golub$PROBEID, ]\n\n# Further subset Golub to B-cell ALL samples\ngolub_bALL <- eset_golub[, pData(eset_golub)$T.B.cell == \"B-cell\" &\n                           pData(eset_golub)$ALL.AML  == \"ALL\"]\n\nfeatureNames(dat_train) <- probe_all$SYMBOL\nrownames(exprs(dat_train)) <- probe_all$SYMBOL\n\nfeatureNames(golub_bALL) <- probe_golub$SYMBOL\nrownames(exprs(golub_bALL)) <- probe_golub$SYMBOL\n\n\n# Confirm feature dimensions\ndim(dat_train)    # features x ALL samples\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFeatures  Samples \n     354       79 \n```\n\n\n:::\n\n```{.r .cell-code}\ndim(golub_bALL)   # features x Golub B-cell ALL samples\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFeatures  Samples \n     354       38 \n```\n\n\n:::\n:::\n\n\n\n\n\n> `dat_train` and `golub_BALL` now share the same gene-symbol feature set, ready for model training and transfer.\n\n## Exploratory Data Analysis\n\nWith our filtered training set (`dat_train`), we explore patterns using a \nheatmap and principal component analysis (PCA).\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set subtype colors for visualization\nfcol <- ifelse(dat_train$mol.biol == \"NEG\", \"gray\", \"steelblue\")\n\nheatmap(exprs(dat_train), ColSideColors = fcol)\n```\n\n::: {.cell-output-display}\n![](Unit03_GeneticData_files/figure-html/unnamed-chunk-3-1.png){width=100%}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# PCA on samples\nPCg <- prcomp(t(exprs(dat_train)))\n\n# Scree plot\nplot(PCg)\n```\n\n::: {.cell-output-display}\n![](Unit03_GeneticData_files/figure-html/unnamed-chunk-4-1.png){width=100%}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scatterplots of PCs\npairs(PCg$x[, 1:5], col = fcol, pch = 19)\n```\n\n::: {.cell-output-display}\n![](Unit03_GeneticData_files/figure-html/unnamed-chunk-5-1.png){width=100%}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Biplot of PC1 vs PC2\nbiplot(PCg) \n```\n\n::: {.cell-output-display}\n![](Unit03_GeneticData_files/figure-html/unnamed-chunk-6-1.png){width=100%}\n:::\n:::\n\n\n\n\n\n> **Interpretation:**\n>\n> * The heatmap reveals distinct blocks of probes whose expression differs between BCR-ABL1 fusion-positive and fusion-negative samples.\n> * The PCA scatter shows separation (or overlap) of samples by fusion status along the first two principal components, and to a lesser extent, the next three.\n> * In the biplot, probes lying far from the origin along PC1 or PC2 represent genes with the largest loadings, i.e., the greatest contribution to those principal components. Samples positioned similarly share expression patterns in those genes.\n> * Overall, the modest separation in PCA indicates the need for supervised methods to pinpoint the genes most predictive of BCR-ABL1 status.\n\n## Train/Test Split and Classifier Training\n\nWe split `dat_train` (ALL) into 60% training and 40% holdout, then train three ML models.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2025)                # for reproducibility\nn_all <- ncol(dat_train)      # number of ALL samples\ntrain_idx <- sample(n_all, size = floor(0.6 * n_all))\n# Training and holdout ExpressionSets\ntrain_eset <- dat_train[, train_idx]\ntest_eset  <- dat_train[, -train_idx]\n```\n:::\n\n\n\n\n\nIn this section, we compare three supervised learning methods using the \n[`MLInterfaces`](https://www.bioconductor.org/packages/devel/bioc/vignettes/MLInterfaces/inst/doc/MLprac2_2.html) \nframework:\n\n* **Diagonal Linear Discriminant Analysis (dldaI)**\n* **Neural Network (nnetI)**\n* **Random Forest (randomForestI)**\n\nWe will use the `MLearn()` function, which wraps each algorithm, providing a \nconsistent interface to train, predict, and evaluate models on an \n`ExpressionSet`. After fitting, we will use `confuMat()` to display the \nconfusion matrix, showing the true versus predicted class counts.\n\nWe train each model on the first 40 most variable probes from the filtered \n`ExpressionSet` (features `1:40` in `train_eset`).\n\n### Diagonal Linear Discriminant Analysis (`dldaI`)\n\nDiagonal LDA assumes each feature is conditionally independent (covariance \nmatrix is diagonal), which can improve stability in high-dimensional, \nlow-sample settings. We use the `dldaI` interface to fit and evaluate this \nclassifier.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Train Diagonal LDA on probes 1:40\ndlda_mod <- MLearn(\n  mol.biol ~ ., # mol.biol ~ . specifies BCR/ABL1 fusion status as the outcome\n  train_eset,   # Filtered ExpressionSet\n  dldaI,        # dldaI is the diagonal LDA interface\n  1:40          # 1:40 selects the first 40 probes\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"mol.biol\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Print a summary of the fitted model\ndlda_mod\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMLInterfaces classification output container\nThe call was:\nMLearn(formula = mol.biol ~ ., data = train_eset, .method = dldaI, \n    trainInd = 1:40)\nPredicted outcome distribution for test set:\n\nBCR/ABL     NEG \n      3       4 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Display the confusion matrix (true vs predicted)\ncm_dlda <- confuMat(dlda_mod)\ncm_dlda\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         predicted\ngiven     BCR/ABL NEG\n  BCR/ABL       3   1\n  NEG           0   3\n```\n\n\n:::\n\n```{.r .cell-code}\n# Accuracy of Diagonal LDA\nacc_dlda <- sum(diag(cm_dlda)) / sum(cm_dlda)\ncat(\"Accuracy:\", sprintf(\"%.2f%%\", acc_dlda * 100))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAccuracy: 85.71%\n```\n\n\n:::\n:::\n\n\n\n\n\n### Neural Network (`nnetI`)\n\nA single hidden layer neural network can capture non-linear relationships. We \nuse the `nnetI` interface with default parameters plus:\n\n* `size = 5`: number of hidden neurons\n\n* `decay = 0.01`: weight-decay regularization\n\n* `MaxNWts = 2000`: maximum allowed number of weights\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Neural Network (nnetI)\nnn_mod <- MLearn(\n  mol.biol ~ ., \n  train_eset, \n  nnetI, \n  1:40, \n  size=5, \n  decay=0.01, \n  MaxNWts=2000\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"mol.biol\"\n# weights:  1781\ninitial  value 31.210991 \niter  10 value 19.645950\niter  20 value 12.779243\niter  30 value 5.459003\niter  40 value 1.841191\niter  50 value 1.334631\niter  60 value 1.133200\niter  70 value 0.875814\niter  80 value 0.704137\niter  90 value 0.625722\niter 100 value 0.610470\nfinal  value 0.610470 \nstopped after 100 iterations\n```\n\n\n:::\n\n```{.r .cell-code}\n# Show model summary\nnn_mod\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMLInterfaces classification output container\nThe call was:\nMLearn(formula = mol.biol ~ ., data = train_eset, .method = nnetI, \n    trainInd = 1:40, size = 5, decay = 0.01, MaxNWts = 2000)\nPredicted outcome distribution for test set:\n\nBCR/ABL     NEG \n      5       2 \nSummary of scores on test set (use testScores() method for details):\n[1] 0.2948988\n```\n\n\n:::\n\n```{.r .cell-code}\n# Confusion matrix for Neural Net\ncm_nn <- confuMat(nn_mod)\ncm_nn\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         predicted\ngiven     BCR/ABL NEG\n  BCR/ABL       4   0\n  NEG           1   2\n```\n\n\n:::\n\n```{.r .cell-code}\n# Accuracy of Neural Net\nacc_nn <- sum(diag(cm_nn)) / sum(cm_nn)\ncat(\"Accuracy:\", sprintf(\"%.2f%%\", acc_nn * 100))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAccuracy: 85.71%\n```\n\n\n:::\n:::\n\n\n\n\n\n### Random Forest (`randomForestI`)\n\nRandom forests build an ensemble of decision trees on bootstrapped samples and \nrandom feature subsets, offering robust performance with little tuning. We use \nthe `randomForestI` to fit a random forest model: \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Random Forest (randomForestI)\nrf_mod <- MLearn(\n  mol.biol ~ ., \n  train_eset, \n  randomForestI, \n  1:40\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"mol.biol\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Show model summary\nrf_mod\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMLInterfaces classification output container\nThe call was:\nMLearn(formula = mol.biol ~ ., data = train_eset, .method = randomForestI, \n    trainInd = 1:40)\nPredicted outcome distribution for test set:\n\nBCR/ABL     NEG \n      4       3 \nSummary of scores on test set (use testScores() method for details):\nBCR/ABL     NEG \n  0.524   0.476 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Confusion matrix\ncm_rf <- confuMat(rf_mod)\ncm_rf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         predicted\ngiven     BCR/ABL NEG\n  BCR/ABL       4   0\n  NEG           0   3\n```\n\n\n:::\n\n```{.r .cell-code}\n# Accuracy of Random Forest\nacc_rf <- sum(diag(cm_rf)) / sum(cm_rf)\ncat(\"Accuracy:\", sprintf(\"%.2f%%\", acc_rf * 100))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAccuracy: 100.00%\n```\n\n\n:::\n:::\n\n\n\n\n\n> **Interpretation:**\n> Only the Random Forest achieves perfect separation in the validation samples. This highlights the challenge of discriminating BCR-ABL1 status based solely on the top variable probes and underscores why downstream IPD corrections (for regression inference) remain valuable.\n\n## Predictions on ALL Test and Golub\n\nAfter fitting our classifiers on the **training** subset of ALL, we now generate predictions on both the **ALL holdout test** and the **Golub B-cell ALL** datasets.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predict BCR-ABL1 status on ALL test holdout using random forest\nall_pred <- MLInterfaces::predict.classifierOutput(rf_mod, test_eset)\n\n# Compare to true labels in test_eset\nconf_mat_test <- table(\n  Truth    = test_eset$mol.biol,\n  Predicted= all_pred$testPredictions\n)\nconf_mat_test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         Predicted\nTruth     BCR/ABL NEG\n  NEG           3  16\n  BCR/ABL      11   2\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predict BCR-ABL1 status on Golub B-cell ALL\ngolub_pred <- MLInterfaces::predict.classifierOutput(rf_mod, golub_bALL)\n\n# Summarize prediction counts (no ground truth in Golub)\ntable(golub_pred$testPredictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nBCR/ABL     NEG \n     25      13 \n```\n\n\n:::\n:::\n\n\n\n\n\n> **Note:** We retain **true** labels in the ALL test set for later IPD; Golub remains **unlabeled**.\n\n## IPD Inference on Sex Effect\n\nWe will now use **Inference with Predicted Data (IPD)** to estimate the log-odds effect of **sex** (male vs female) on true BCR-ABL1 status, combining the holdout ALL data with true and predict fusion status (i.e., our labeled data) and the Golub data with the predicted fusion status (i.e., our unlabeled data)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Build labeled (ALL test) data frame\ndf_test <- tibble(\n  sample = colnames(test_eset),\n  set    = \"labeled\",\n  true   = as.integer(test_eset$mol.biol == \"BCR/ABL\"),\n  pred   = as.integer(all_pred$testPredictions == \"BCR/ABL\"),\n  sex    = factor(pData(test_eset)$sex, levels = c(\"F\",\"M\"))\n)\n\n# Build unlabeled (Golub) data frame\ndf_golub <- tibble(\n  sample = colnames(golub_bALL),\n  set    = \"unlabeled\",\n  true   = NA_real_,\n  pred   = as.integer(golub_pred$testPredictions == \"BCR/ABL\"),\n  sex    = factor(pData(golub_bALL)$Gender, levels = c(\"F\",\"M\"))\n)\n\n# Combine for IPD\nipd_df <- bind_rows(df_test, df_golub) |> drop_na(sex)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Classical regression\nclass_fit <- glm(true ~ sex, \"binomial\", df_test)\nclass_df  <- broom::tidy(class_fit) |>\n  mutate(method = \"Classical\")\n\n# Naive regression\nnaive_fit <- glm(pred ~ sex, \"binomial\", df_golub)\nnaive_df  <- broom::tidy(naive_fit) |>\n  mutate(method = \"Naive\")\n\n# IPD logistic regression\nipd_fit <- ipd(\n  formula   = true - pred ~ sex,\n  method    = \"pspa\",\n  model     = \"logistic\",\n  data      = ipd_df,\n  label     = \"set\",\n)\nipd_df  <- tidy(ipd_fit) |>\n  mutate(method = \"IPD\")\n\n# Summarize coefficients\ncombined <- bind_rows(class_df, naive_df, ipd_df) |>\n  mutate(term = recode(term, \"sexM\" = \"Male (vs Female)\"))\n\n# Forest plot\nggplot(combined, aes(x = estimate, y = term, color = method)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_errorbarh(aes(xmin = estimate - 1.96 * std.error,\n                     xmax = estimate + 1.96 * std.error),\n                 height = 0.2,\n                 position = position_dodge(width = 0.6)) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  scale_y_discrete(limits = rev) +\n  scale_fill_manual(values  = c(\"#1B365D\", \"#00C1D5\", \"#AA4AC4\")) +\n  scale_color_manual(values = c(\"#1B365D\", \"#00C1D5\", \"#AA4AC4\")) +\n  labs(\n    x = \"Log-Odds Estimate (95% CI)\",\n    y = \"Covariate\",\n    title = \"Comparison of BCR-ABL1 Model Coefficients\",\n    color = \"Model Type\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: `geom_errorbarh()` was deprecated in ggplot2 4.0.0.\nâ„¹ Please use the `orientation` argument of `geom_errorbar()` instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`height` was translated to `width`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Unit03_GeneticData_files/figure-html/unnamed-chunk-14-1.png){width=100%}\n:::\n:::\n\n\n\n\n\n> **Insight:** By treating the ALL test set as labeled and Golub as unlabeled, IPD  combines information across cohorts to correct bias and improve precision when estimating the association between BCR-ABL1 status and patient sex.\n\n---\n\n*This is the end of the module. We hope this was informative! For question/concerns/suggestions, please reach out to ssalerno@fredhutch.org*\n",
    "supporting": [
      "Unit03_GeneticData_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}